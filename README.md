# ğŸš€ LLM Streaming Demo - å¤§æ¨¡å‹æµå¼å“åº”å¤„ç†

[![Java](https://img.shields.io/badge/Java-8+-blue.svg)](https://www.oracle.com/java/)
[![Spring Boot](https://img.shields.io/badge/Spring%20Boot-2.x-green.svg)](https://spring.io/projects/spring-boot)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![Stars](https://img.shields.io/github/stars/yourusername/llm-streaming-demo.svg)](https://github.com/yourusername/llm-streaming-demo/stargazers)

## ğŸ“– é¡¹ç›®ç®€ä»‹

ä¸€ä¸ªåŸºäºSpring Bootçš„å¤§æ¨¡å‹æµå¼å“åº”å¤„ç†demoï¼Œæ”¯æŒå­—ç¬¦çº§è¾“å‡ºæ•ˆæœï¼Œæä¾›å®Œæ•´çš„APIé›†æˆæ–¹æ¡ˆå’Œå®æ—¶æµ‹è¯•ç•Œé¢ã€‚è¯¥é¡¹ç›®å±•ç¤ºäº†å¦‚ä½•å®ç°æµå¼æ•°æ®å¤„ç†ã€å­—ç¬¦çº§è¾“å‡ºæ•ˆæœï¼Œä»¥åŠå¦‚ä½•é›†æˆç¬¬ä¸‰æ–¹å¤§æ¨¡å‹APIã€‚

## âœ¨ æ ¸å¿ƒç‰¹æ€§

- ğŸ”„ **æµå¼æ•°æ®å¤„ç†**: æ”¯æŒå®æ—¶æµå¼å“åº”ï¼Œæ— éœ€ç­‰å¾…å®Œæ•´å“åº”
- ğŸ“ **å­—ç¬¦çº§è¾“å‡º**: æ¯ä¸ªå­—ç¬¦ç‹¬ç«‹å‘é€ï¼Œå®ç°æ‰“å­—æœºæ•ˆæœ
- ğŸ”Œ **å¤šAPIæ”¯æŒ**: æ”¯æŒç™¾åº¦åƒå¸†ã€OpenAIã€é˜¿é‡Œäº‘ç­‰å¤šç§å¤§æ¨¡å‹API
- ğŸ¨ **å®æ—¶æµ‹è¯•ç•Œé¢**: æä¾›Webç•Œé¢è¿›è¡Œå®æ—¶æµ‹è¯•
- ğŸ“Š **å®Œå–„é”™è¯¯å¤„ç†**: åŒ…å«å®Œæ•´çš„å¼‚å¸¸å¤„ç†å’Œé™çº§æ–¹æ¡ˆ
- âš¡ **é«˜æ€§èƒ½**: åŸºäºOkHttpï¼Œæ”¯æŒé•¿è¿æ¥å’Œæµå¼å“åº”

## ğŸ› ï¸ æŠ€æœ¯æ ˆ

- **åç«¯**: Spring Boot 2.x, OkHttp 4.x, Fastjson2
- **å‰ç«¯**: HTML5, JavaScript, CSS3
- **æ„å»ºå·¥å…·**: Maven 3.6+
- **è¿è¡Œç¯å¢ƒ**: JDK 8+

## ğŸ“¦ å¿«é€Ÿå¼€å§‹

### ç¯å¢ƒè¦æ±‚

- JDK 8 æˆ–æ›´é«˜ç‰ˆæœ¬
- Maven 3.6 æˆ–æ›´é«˜ç‰ˆæœ¬
- æœ‰æ•ˆçš„å¤§æ¨¡å‹APIå¯†é’¥

### å®‰è£…æ­¥éª¤

1. **å…‹éš†é¡¹ç›®**
```bash
git clone https://github.com/yourusername/llm-streaming-demo.git
cd llm-streaming-demo
```

2. **é…ç½®APIå¯†é’¥**
```yaml
# åœ¨ application.yml ä¸­é…ç½®
llm:
  api:
    key: your-api-key-here
    url: https://api.example.com
    model: gpt-3.5-turbo
```

3. **å¯åŠ¨åº”ç”¨**
```bash
# ä½¿ç”¨Mavenå¯åŠ¨
mvn spring-boot:run

# æˆ–ä½¿ç”¨å¯åŠ¨è„šæœ¬
chmod +x scripts/start.sh
./scripts/start.sh
```

4. **è®¿é—®æµ‹è¯•é¡µé¢**
æ‰“å¼€æµè§ˆå™¨è®¿é—®: `http://localhost:8080/stream-test.html`

## ğŸš€ ä½¿ç”¨è¯´æ˜

### APIæ¥å£

```http
GET /api/stream/llm?prompt=ä½ çš„é—®é¢˜&charLevel=true&maxTokens=500
```

**å‚æ•°è¯´æ˜:**
- `prompt`: æç¤ºè¯ï¼ˆå¿…å¡«ï¼‰
- `charLevel`: æ˜¯å¦å­—ç¬¦çº§è¾“å‡ºï¼ˆå¯é€‰ï¼Œé»˜è®¤trueï¼‰
- `maxTokens`: æœ€å¤§tokenæ•°ï¼ˆå¯é€‰ï¼Œé»˜è®¤500ï¼‰

**å“åº”æ ¼å¼:**
```json
{"dataId":"uuid","dataType":"LLM_RESPONSE","content":"ä½ ","finished":false}
{"dataId":"uuid","dataType":"LLM_RESPONSE","content":"å¥½","finished":false}
{"dataId":"uuid","dataType":"LLM_RESPONSE","content":"ï¼Œ","finished":false}
```

### æµ‹è¯•é¡µé¢åŠŸèƒ½

- å®æ—¶è¾“å…¥æç¤ºè¯
- æŸ¥çœ‹å­—ç¬¦çº§æµå¼è¾“å‡º
- ç›‘æ§å“åº”çŠ¶æ€
- é”™è¯¯ä¿¡æ¯æ˜¾ç¤º

## ğŸ”§ é…ç½®è¯´æ˜

### æ”¯æŒçš„API

#### 1. ç™¾åº¦åƒå¸†
```yaml
llm:
  api:
    key: your-baidu-api-key
    url: https://qianfan.baidubce.com/v2/chat/completions
    model: ernie-speed-pro-128k
```

#### 2. OpenAI
```yaml
llm:
  api:
    key: your-openai-api-key
    url: https://api.openai.com/v1/chat/completions
    model: gpt-3.5-turbo
```

#### 3. é˜¿é‡Œäº‘
```yaml
llm:
  api:
    key: your-aliyun-api-key
    url: https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation
    model: qwen-turbo
```

### ç¯å¢ƒå˜é‡é…ç½®

```bash
export LLM_API_KEY=your-api-key
export LLM_API_URL=https://api.example.com
export LLM_MODEL=gpt-3.5-turbo
```

## ğŸ“Š é¡¹ç›®ç»“æ„

```
llm-streaming-demo/
â”œâ”€â”€ src/main/java/com/demo/llmstreaming/
â”‚   â”œâ”€â”€ controller/           # æ§åˆ¶å™¨å±‚
â”‚   â”‚   â””â”€â”€ StreamController.java
â”‚   â”œâ”€â”€ service/             # æœåŠ¡å±‚
â”‚   â”‚   â”œâ”€â”€ StreamService.java
â”‚   â”‚   â””â”€â”€ MsgCallback.java
â”‚   â”œâ”€â”€ vo/                  # æ•°æ®ä¼ è¾“å¯¹è±¡
â”‚   â”‚   â””â”€â”€ StreamResponseVO.java
â”‚   â”œâ”€â”€ config/              # é…ç½®ç±»
â”‚   â”‚   â””â”€â”€ StreamConfiguration.java
â”‚   â””â”€â”€ LlmStreamingApplication.java  # ä¸»å¯åŠ¨ç±»
â”œâ”€â”€ src/main/resources/
â”‚   â”œâ”€â”€ static/              # é™æ€èµ„æº
â”‚   â”‚   â””â”€â”€ stream-test.html
â”‚   â”œâ”€â”€ application.yml      # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ application.properties
â”œâ”€â”€ scripts/                 # æµ‹è¯•è„šæœ¬
â”‚   â”œâ”€â”€ start.sh
â”‚   â”œâ”€â”€ test-api.sh
â”‚   â”œâ”€â”€ test-char-level.sh
â”‚   â””â”€â”€ verify-api-key.sh
â”œâ”€â”€ docs/                    # æ–‡æ¡£
â”‚   â”œâ”€â”€ API_INTEGRATION_GUIDE.md
â”‚   â””â”€â”€ DEPLOYMENT_GUIDE.md
â”œâ”€â”€ pom.xml                  # Mavené…ç½®
â””â”€â”€ README.md               # é¡¹ç›®è¯´æ˜
```

## ğŸ¯ æ ¸å¿ƒå®ç°

### æµå¼æ•°æ®å¤„ç†æµç¨‹

```
APIå“åº” â†’ è§£æJSON â†’ å­—ç¬¦çº§æ‹†åˆ† â†’ é€å­—ç¬¦è¾“å‡º
```

### å­—ç¬¦çº§è¾“å‡ºå®ç°

```java
// å­—ç¬¦çº§å¤„ç†ï¼šå°†æ¶ˆæ¯æ‹†åˆ†æˆå•ä¸ªå­—ç¬¦
for (int i = 0; i < message.length(); i++) {
    char ch = message.charAt(i);
    String charStr = String.valueOf(ch);
    
    StreamResponseVO data = StreamResponseVO.createData(
        dataId, "LLM_RESPONSE", charStr, null);
    data.setFinished(false);
    
    String jsonData = objectMapper.writeValueAsString(data);
    writer.write(jsonData + "\n");
    writer.flush();
    
    // æ·»åŠ å»¶è¿Ÿï¼Œå®ç°æ‰“å­—æœºæ•ˆæœ
    Thread.sleep(50);
}
```

## ğŸ§ª æµ‹è¯•

### ä½¿ç”¨æµ‹è¯•è„šæœ¬

```bash
# åŸºç¡€APIæµ‹è¯•
./scripts/test-api.sh

# å­—ç¬¦çº§è¾“å‡ºæµ‹è¯•
./scripts/test-char-level.sh

# APIå¯†é’¥éªŒè¯
./scripts/verify-api-key.sh
```

### ä½¿ç”¨curlæµ‹è¯•

```bash
curl -X GET "http://localhost:8080/api/stream/llm?prompt=ä½ å¥½ï¼Œè¯·ä»‹ç»ä¸€ä¸‹è‡ªå·±" \
  -H "Accept: application/json" \
  --no-buffer
```

## ğŸš¨ æ³¨æ„äº‹é¡¹

1. **APIå¯†é’¥å®‰å…¨**: è¯·å¦¥å–„ä¿ç®¡APIå¯†é’¥ï¼Œä¸è¦æäº¤åˆ°ä»£ç ä»“åº“
2. **ç½‘ç»œè¿æ¥**: ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šï¼Œæ”¯æŒé•¿è¿æ¥
3. **èµ„æºç®¡ç†**: åŠæ—¶å…³é—­HTTPè¿æ¥ï¼Œé¿å…èµ„æºæ³„æ¼
4. **é”™è¯¯å¤„ç†**: æ³¨æ„å¤„ç†APIé”™è¯¯å’Œç½‘ç»œå¼‚å¸¸

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### è¿æ¥æ± é…ç½®
```yaml
llm:
  api:
    timeout: 60000
    max-connections: 100
    keep-alive: 30000
```

### çº¿ç¨‹æ± é…ç½®
```yaml
spring:
  task:
    execution:
      pool:
        core-size: 10
        max-size: 50
        queue-capacity: 200
```

## ğŸ³ Dockeréƒ¨ç½²

### æ„å»ºé•œåƒ
```bash
mvn clean package -DskipTests
docker build -t llm-streaming-demo:1.0.0 .
```

### è¿è¡Œå®¹å™¨
```bash
docker run -d \
  --name llm-streaming-demo \
  -p 8080:8080 \
  -e LLM_API_KEY=your-api-key \
  llm-streaming-demo:1.0.0
```

## â˜¸ï¸ Kuberneteséƒ¨ç½²

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: llm-streaming-demo
spec:
  replicas: 3
  selector:
    matchLabels:
      app: llm-streaming-demo
  template:
    metadata:
      labels:
        app: llm-streaming-demo
    spec:
      containers:
      - name: llm-streaming-demo
        image: llm-streaming-demo:1.0.0
        ports:
        - containerPort: 8080
        env:
        - name: LLM_API_KEY
          value: "your-api-key"
```

## ğŸ¤ è´¡çŒ®

æ¬¢è¿æäº¤Issueå’ŒPull Requestï¼

### è´¡çŒ®æŒ‡å—

1. Fork æœ¬ä»“åº“
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. æ‰“å¼€ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ - æŸ¥çœ‹ [LICENSE](LICENSE) æ–‡ä»¶äº†è§£è¯¦æƒ…

## â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStarï¼

## ğŸ“ è”ç³»æ–¹å¼

- ä½œè€…: Your Name
- é‚®ç®±: your.email@example.com
- GitHub: [@yourusername](https://github.com/yourusername)

## ğŸ™ è‡´è°¢

æ„Ÿè°¢æ‰€æœ‰ä¸ºè¿™ä¸ªé¡¹ç›®åšå‡ºè´¡çŒ®çš„å¼€å‘è€…ï¼

---

**â­ å¦‚æœè¿™ä¸ªé¡¹ç›®å¯¹ä½ æœ‰å¸®åŠ©ï¼Œè¯·ç»™ä¸ªStaræ”¯æŒä¸€ä¸‹ï¼**

