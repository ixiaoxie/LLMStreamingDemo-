# LLM Streaming Demo 配置文件
server:
  port: 8080
  servlet:
    context-path: /

# 应用配置
spring:
  application:
    name: llm-streaming-demo
  profiles:
    active: dev

# LLM API 配置
llm:
  api:
    # API密钥 - 请替换为您的实际API密钥
    # 支持环境变量: ${LLM_API_KEY:YOUR_API_KEY}
    key: ${LLM_API_KEY:YOUR_API_KEY}
    
    # API地址 - 请根据您使用的服务商替换
    # 百度千帆: https://qianfan.baidubce.com/v2/chat/completions
    # OpenAI: https://api.openai.com/v1/chat/completions
    # 阿里云: https://dashscope.aliyuncs.com/api/v1/services/aigc/text-generation/generation
    url: ${LLM_API_URL:https://qianfan.baidubce.com/v2/chat/completions}
    
    # 模型名称 - 请根据您使用的服务商替换
    # 百度千帆: ernie-speed-pro-128k, ernie-3.5-8k
    # OpenAI: gpt-3.5-turbo, gpt-4
    # 阿里云: qwen-turbo, qwen-plus
    model: ${LLM_MODEL:ernie-speed-pro-128k}
    
    # 请求超时时间（毫秒）
    timeout: ${LLM_API_TIMEOUT:60000}

# 日志配置
logging:
  level:
    com.demo.llmstreaming: INFO
    org.springframework.web: INFO
  pattern:
    console: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
    file: "%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n"
  file:
    name: logs/llm-streaming-demo.log

# Swagger配置
springfox:
  documentation:
    swagger:
      v2:
        path: /api-docs

